{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mission - Classifiez automatiquement des informations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous êtes mandaté en tant que Consultant Data Scientist par le département RH de votre client. Il s’agit de l'ESN TechNova Partners, spécialisée dans le conseil en transformation digitale et la vente d’applications en SaaS.\n",
    " \n",
    "Ils font face à un turnover plus élevé que d'habitude et ils souhaitent identifier les causes racines potentielles derrière ces démissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies \"classiques\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Librairies scikit-learn\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    GridSearchCV, \n",
    "    cross_validate,\n",
    ")\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error \n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "#Preprocess\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "#Modèles\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On reprend les éléments du précédent notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees_modelisation = pd.read_csv(\"../Data/Projet_4_etape2_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 - Réalisation d'un premier modèle de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommandation : Commencer par réaliser une séparation train test simple ou une validation croisée simple.\n",
    "### Recommandation : Commencer par entraîner d’abord un modèle Dummy, puis un modèle linéaire, avant d'entraîner un modèle non-linéaire. Cela vous permettra d’évaluer la difficulté et la “non-linéarité” du jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps, nous allons procéder à une validation croisée sur un modèle Dummy pour avoir une base de comparaison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur le modèle DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DummyClassifier est un classificateur qui fait des prédictions à l'aide de règles simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Résultats CV (train vs val) ===\n",
      "accuracy : train 0.838 ± 0.001 | val 0.838 ± 0.001\n",
      "precision: train 0.000 ± 0.000 | val 0.000 ± 0.000\n",
      "recall   : train 0.000 ± 0.000 | val 0.000 ± 0.000\n",
      "f1       : train 0.000 ± 0.000 | val 0.000 ± 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/florianschorer/OpenClassrooms Project/Classifiez_automatiquement_des_informations/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à scaler ou déjà encodées\n",
    "features_a_scaler = [\n",
    "    'revenu_mensuel','annee_experience_totale','annees_dans_l_entreprise','distance_domicile_travail',\n",
    "    'annees_depuis_la_derniere_promotion','experience_externe','score_satisfaction',\n",
    "    'augmentation_par_formation','pee_par_anciennete','niveau_education']\n",
    "features_encodees = [\n",
    "    'genre','heure_supplementaires',\n",
    "    'frequence_deplacement','a_suivi_formation','tranche_age','statut_marital_Celibataire',\n",
    "    'statut_marital_Divorce','statut_marital_Marie','promotion_recente','poste_AssistantdeDirection',\n",
    "    'poste_CadreCommercial','poste_Consultant','poste_DirecteurTechnique','poste_Manager',\n",
    "    'poste_ReprésentantCommercial','poste_RessourcesHumaines','poste_SeniorManager','poste_TechLead']\n",
    "\n",
    "# Séparation de X et y\n",
    "y = donnees_modelisation[\"a_quitte_l_entreprise\"]\n",
    "X = donnees_modelisation.drop(columns = \"a_quitte_l_entreprise\")\n",
    "\n",
    "# Split en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42, stratify=y)\n",
    "\n",
    "# Scaling ou non de mes features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), features_a_scaler),\n",
    "        ('cat', 'passthrough', features_encodees)\n",
    "    ]\n",
    ")\n",
    "# Ajout dans un Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "# Enregistrement de nos indicateurs\n",
    "scoring = ['accuracy','precision','recall','f1']\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline,\n",
    "    X_train, y_train,            \n",
    "    cv=3,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"=== Résultats CV (train vs val) ===\")\n",
    "for metric in scoring:\n",
    "    tr = cv_results[f\"train_{metric}\"]\n",
    "    te = cv_results[f\"test_{metric}\"]\n",
    "    print(f\"{metric:9s}: train {tr.mean():.3f} ± {tr.std():.3f} | val {te.mean():.3f} ± {te.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant d'interpréter nos indicateurs, une petite définition pour chaque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy : C’est le pourcentage de prédictions correctes (tous labels confondus). Exemple : \"Parmi tous les employés, combien ai-je bien classés ?”\n",
    "\n",
    "* Precison : Mesure la fiabilité des prédictions positives. Exemple : “Sur tous ceux que je pense quitter l’entreprise, combien quittent vraiment ?”\n",
    "* Recall : Mesure la capacité à ne pas rater de cas positifs. Exemple “Sur tous les départs réels, combien ai-je détectés ?”\n",
    "* F1-score : C’est une moyenne entre Precision et Recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* C'est ce qu'on attend d'un modèle de ce type, il va nous servir de base. Nous avons un dataset déséquilibré, 83,8% des salariés sont restés, et nous avons un accuracy de 83,8%, cela correspond.\n",
    "* Precision / Recall / F1 = 0. Le modèle ne prédit jamais la classe “Oui” → donc impossible de calculer la précision ou le rappel pour cette classe : affichage du warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sur le modèle LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Résultats CV (train vs val) ===\n",
      "accuracy : train 0.880 ± 0.005 | val 0.881 ± 0.013\n",
      "precision: train 0.786 ± 0.029 | val 0.791 ± 0.096\n",
      "recall   : train 0.355 ± 0.034 | val 0.358 ± 0.043\n",
      "f1       : train 0.488 ± 0.031 | val 0.492 ± 0.059\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à scaler ou déjà encodées\n",
    "features_a_scaler = [\n",
    "    'revenu_mensuel','annee_experience_totale','annees_dans_l_entreprise','distance_domicile_travail',\n",
    "    'annees_depuis_la_derniere_promotion','experience_externe','score_satisfaction',\n",
    "    'augmentation_par_formation','pee_par_anciennete','niveau_education']\n",
    "features_encodees = [\n",
    "    'genre','heure_supplementaires',\n",
    "    'frequence_deplacement','a_suivi_formation','tranche_age','statut_marital_Celibataire',\n",
    "    'statut_marital_Divorce','statut_marital_Marie','promotion_recente','poste_AssistantdeDirection',\n",
    "    'poste_CadreCommercial','poste_Consultant','poste_DirecteurTechnique','poste_Manager',\n",
    "    'poste_ReprésentantCommercial','poste_RessourcesHumaines','poste_SeniorManager','poste_TechLead']\n",
    "\n",
    "# Séparation de X et y\n",
    "y = donnees_modelisation[\"a_quitte_l_entreprise\"]\n",
    "X = donnees_modelisation.drop(columns = \"a_quitte_l_entreprise\")\n",
    "\n",
    "# Split en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42, stratify=y)\n",
    "\n",
    "# Scaling ou non de mes features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('num', StandardScaler(), features_a_scaler ),\n",
    "        ('cat', 'passthrough', features_encodees)\n",
    "    ]\n",
    ")\n",
    "# Ajout dans un Pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "# Enregistrement de nos indicateurs\n",
    "scoring = ['accuracy','precision','recall','f1']\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    pipeline,\n",
    "    X_train, y_train,            \n",
    "    cv=3,\n",
    "    scoring=scoring,\n",
    "    return_train_score=True # On inclut les scores du train\n",
    ")\n",
    "\n",
    "print(\"=== Résultats CV (train vs val) ===\")\n",
    "for metric in scoring:\n",
    "    tr = cv_results[f\"train_{metric}\"]\n",
    "    te = cv_results[f\"test_{metric}\"]\n",
    "    print(f\"{metric:9s}: train {tr.mean():.3f} ± {tr.std():.3f} | val {te.mean():.3f} ± {te.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy : train 0.880 vs val 0.881. Le modèle classe correctement environ 88 % des salariés, aussi bien sur train que sur validation. L’écart train/val est quasi nul : pas d’overfitting. On peut noter également un meilleur score d'accuracy pour le modèle de régression logistique que notre étalon Dummy.\n",
    "\n",
    "* Precision : train 0.786 vs val 0.791. Quand le modèle prédit “Oui” (départ), il a raison environ 8 fois sur 10. Donc peu de faux positifs (il ne se trompe pas souvent en disant qu’un salarié part).\n",
    "* Recall : train 0.355 vs val 0.358. Mais il ne détecte qu’environ 1 salarié sur 3 qui part réellement. Beaucoup de faux négatifs : le modèle loupe une majorité des départs.\n",
    "* F1 : train 0.488 | val 0.492. Le compromis précision/rappel est moyen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classifiez_automatiquement_des_informations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
